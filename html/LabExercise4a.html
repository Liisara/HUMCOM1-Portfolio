<html>
    <title>GeForce RTX by Mark Cyrus</title>
        <style>
            .Title {font-family: Arial, Helvetica, sans-serif;}
            .Subtitle {font-family: Arial, Helvetica, sans-serif;}
            .Body {font-family: Arial, Helvetica, sans-serif;
                   font-size: 20px;}
            .First {text-align: justify;
                    font-size: 15px;
                    font-family: Arial, Helvetica, sans-serif;}
            .Body1 {background-color: blanchedalmond;}
            .Reference {font-style: italic;}
            
        </style>
    <body class="Body1">
            <h1 class="Title">GeForce RTX 5090 vs. RTX 4090</h1>
                <h2 class="Subtitle">Nvidia's RTX 4090 still puts up an impressive battle against the new RTX 5090</h2>
                <h3><a href="mailto:20244548@s.ubaguio.edu">By: Mark Cyrus P. Macaraeg</a>
                <a href="https://www.digitaltrends.com/computing/nvidia-geforce-rtx-4090-review/"></a>
                <hr size="3"; color="black">
                <head class="Body">Article Body</head>

                        <p class="First">&emsp;&emsp;&emsp;&emsp;Nvidia’s new flagship is here. The RTX 5090 is real, in the flesh, and it’s as bonkers as Nvidia’s early announcements 
— even <br>if the extreme performance claims come with a few new caveats. But is the generational uplift enough to warrant the increased 
price?<br> And is it worth upgrading from the last-generation king, the <a href="https://www.digitaltrends.com/computing/nvidia-geforce-rtx-4090-review/">RTX 4090</a>? That card is no slouch, and until now, it was the fastest 
graphics <br> card the world had ever seen, and it will remain a fantastic gaming GPU for many years to come.
                        </p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;Today you can find <a href="https://www.nvidia.com/en-us/">Nvidia</a> Founders Edition 4090s for that same price, with third-party options ranging from $1,500 up 
to $2,000 <br>for those with the most advanced cooling solutions. Nvidia has defended the price, of course, 
but we won’t know for sure how much extra value <br> it offers until we’re able to see it more in action.
                        </p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;The <a href="https://www.nvidia.com/en-ph/geforce/graphics-cards/50-series/rtx-5090/">RTX 5090</a> is a big generational uplift in a number of ways. It’s got 33% more CUDA cores, 
which should lead to a strong improvement<br> in general rasterization performance over the 4090.
                        </p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;There are more of a new-generation of RT and Tensor cores, too, which will work well with the new <a href="https://developer.nvidia.com/cuda-zone#:~:text=CUDA%C2%AE%20is%20a%20parallel,harnessing%20the%20power%20of%20GPUs.">CUDA</a> cores to make sure ray tracing doesn’t <br> impact this 
card quite as much as its predecessors. Tensor cores are based on a new fifth-generation design. With more of them, too, we can assume<br> even greater FPS uplifts from but 
those cores are also there to handle the new multi frame generation technology that is currently an exclusive<br> feature of the RTX 50-series.
                        </p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;On the memory front, the RTX 5090 sports a new generation of <a href="https://www.micron.com/products/memory/graphics-memory/gddr7">GDDR7</a> video memory, and 50% more of it, with 32GB. It’s much faster, at 30Gbps,<br> delivering a near 80% 
improvement in overall memory bandwidth. That’s massive overkill for gaming, perhaps betraying this card’s design as more<br> of a Titan-esque card, than a flagship gaming GPU — even if it is likely 
to be the fastest card of its generation.
                        </p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;Nvidia made some grandiose claims about the performance of all its RTX 50-series cards, and while they may be some technical truth to them, <br>it’s not as clear cut as 
Team Green would have you believe. When we tested the card for our review, we found that Nvidia’s claims of 200% 4090<br> performance were overblown outside of very specific <a href="https://www.corsair.com/us/en/explorer/gamer/gaming-pcs/what-is-nvidia-dlss/?srsltid=AfmBOoqPn-pk1B80g6GUY2F1O0knGaAuxbCjym14Qu2mwQDOJ_Ny37zz">DLSS</a> and frame generation-supporting titles. 
In reality, the raw performance uplift is more<br> like 30% when you don’t factor multi frame generation.</p>
                        <p class="First">&emsp;&emsp;&emsp;&emsp;The RTX 5090 isn’t quite on sale yet, but it’s very close. Certainly close enough that it’s worth waiting for if you’re in the market for the best graphics<br> card money 
can buy, because that’s what it is. It’s faster than the RTX 4090 and its multi frame generation support gives it a unique feature that will<br> really help smooth out frame rates as the technology improves. 
Its newer RT and <a href="https://www.digitalocean.com/community/tutorials/understanding-tensor-cores">Tensor cores</a> make raytracing a toggleable option as and when you want it,<br> rather than a frame rate killer, too, which is really nice to see after so 
many generations of lacklustre RT performance.</p>
            <hr size="3"; color="black">
                <pre>
    <p class="Reference">References:</p>
    <a href="https://www.digitaltrends.com/computing/nvidia-geforce-rtx-4090-review/">RTX 4090</a>
    <a href="https://www.nvidia.com/en-us/">Nvidia</a>
    <a href="https://www.nvidia.com/en-ph/geforce/graphics-cards/50-series/rtx-5090/">RTX 5090</a>
    <a href="https://developer.nvidia.com/cuda-zone#:~:text=CUDA%C2%AE%20is%20a%20parallel,harnessing%20the%20power%20of%20GPUs.">CUDA</a>
    <a href="https://www.micron.com/products/memory/graphics-memory/gddr7">GDDR7</a>
    <a href="https://www.corsair.com/us/en/explorer/gamer/gaming-pcs/what-is-nvidia-dlss/?srsltid=AfmBOoqPn-pk1B80g6GUY2F1O0knGaAuxbCjym14Qu2mwQDOJ_Ny37zz">DLSS</a>
    <a href="https://www.digitalocean.com/community/tutorials/understanding-tensor-cores">Tensor cores</a>
                </pre>
        </body>
</html>